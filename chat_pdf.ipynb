{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be7a34f9-451a-445f-a988-c0d1b870b286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Findings of the Association for Computational Linguistics: ACL 2023 , pages 3923–3931July 9-14, 2023 ©2023 Association for Computational LinguisticsA Simple Yet Strong Domain-Agnostic De-bias Methodfor Zero-Shot Sentiment ClassificationYang Zhao†, Tetsuya Nasukawa†, Masayasu Muraoka†, and Bishwaranjan Bhattacharjee♢†IBM Research - Tokyo, 19-21 Nihonbashi Hakozaki-cho, Chuo City, Tokyo, 103-8510, Japan,♢IBM Research, Yorktown Heights, New York 10598, USAyangzhao@ibm.com ,{nasukawa,mmuraoka}@jp.ibm.com ,bhatta@us.ibm.comAbstractZero-shot prompt-based learning has mademuch progress in sentiment analysis, and con-siderable effort has been dedicated to design-ing high-performing prompt templates. How-ever, two problems exist; First, large languagemodels are often biased to their pre-trainingdata, leading to poor performance in prompttemplates that models have rarely seen. Sec-ond, in order to adapt to different domains, re-designing prompt templates is usually required,which is time-consuming and inefficient. Toremedy both shortcomings, we propose a sim-ple yet strong data construction method to de-bias a given prompt template, yielding a largeperformance improvement in sentiment analy-sis tasks across different domains, pre-trainedlanguage models, and prompt templates. Also,we demonstrate the advantage of using domain-agnostic generic responses over the in-domainground-truth data. We release the code here1.1 IntroductionOver the past few years, zero-shot prompt-basedlearning has become a de facto standard in manyNatural Language Processing (NLP) tasks wheretraining data is unavailable. For sentiment analysis,much effort has also been dedicated to designingeffective prompt templates to trigger the capabil-ity of Large Language Models (LLMs) such asRoBERTa (Liu et al., 2019) and GPT (Radfordet al., 2018) to predict sentiment polarities, e.g.,positive or negative. A prompt template typicallyconsists of prompt text and a label token set corre-sponding to the sentiment class. Gao et al. (2021)demonstrates that It was {good,ok,bad}. is a high-performing prompt template for sentiment analy-sis task. As Figure 1 shows, the input to LLM isA must-watch movie. It was [MASK]. , and the to-kenokis the most probable word over the labeltoken set.1https://github.com/repo4nlp/BackgroundIBM Confidential30.020.003…0.01goodokayaof…badPre-trained LMI really love this movie. It was [MASK].[MASK]Probability in softmax layer over vocabulary [1] BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, NAACL 2019IBM Research -Tokyogoodok……badLarge Language Model(frozen)A must-watch movie. It was [MASK].[MASK]probability distrution over vocabgood -> positive ok ->neutral bad -> negativeprobability rescaling, WFigure 1: Zero-shot prompt-based sentiment classifica-tion for a masked language model. The prompt is Itwas [MASK]. and the label token set is {good,ok,bad}which respectively stands for positive/neutral/negativesentiment polarities.However, two problems remain. First, an LLMis often biased to its pre-training data, leading topoor performance in prompt templates that theLLM have rarely seen. Second, when it comesto different domains, such as financial and food,re-designing appropriate prompt templates to adaptto new domains is usually required, which is time-consuming and inefficient. To mitigate the firstproblem, Zhao et al. (2021) proposed a probabilityrescaling method to calibrate the probability basedon the assumption that LLMs should NOT expresseither positive or negative sentiment when the inputis a meaningless sentence such as N/A.Motivated by this, we relax their assumptionand further hypothesize that a good LLM shouldbe capable of accurately predicting the sentimentof an \"absolute\" positive, neutral, or negative sen-tence. For example, the phrase \"thank you somuch\" mostly manifests an \"absolutely\" positive3923', metadata={'page': 0, 'source': '2023.findings-acl.242.pdf'}), Document(page_content='Findings of the Association for Computational Linguistics: ACL 2023 , pages 3923–3931July 9-14, 2023 ©2023 Association for Computational LinguisticsA Simple Yet Strong Domain-Agnostic De-bias Methodfor Zero-Shot Sentiment ClassificationYang Zhao†, Tetsuya Nasukawa†, Masayasu Muraoka†, and Bishwaranjan Bhattacharjee♢†IBM Research - Tokyo, 19-21 Nihonbashi Hakozaki-cho, Chuo City, Tokyo, 103-8510, Japan,♢IBM Research, Yorktown Heights, New York 10598, USAyangzhao@ibm.com ,{nasukawa,mmuraoka}@jp.ibm.com ,bhatta@us.ibm.comAbstractZero-shot prompt-based learning has mademuch progress in sentiment analysis, and con-siderable effort has been dedicated to design-ing high-performing prompt templates. How-ever, two problems exist; First, large languagemodels are often biased to their pre-trainingdata, leading to poor performance in prompttemplates that models have rarely seen. Sec-ond, in order to adapt to different domains, re-designing prompt templates is usually required,which is time-consuming and inefficient. Toremedy both shortcomings, we propose a sim-ple yet strong data construction method to de-bias a given prompt template, yielding a largeperformance improvement in sentiment analy-sis tasks across different domains, pre-trainedlanguage models, and prompt templates. Also,we demonstrate the advantage of using domain-agnostic generic responses over the in-domainground-truth data. We release the code here1.1 IntroductionOver the past few years, zero-shot prompt-basedlearning has become a de facto standard in manyNatural Language Processing (NLP) tasks wheretraining data is unavailable. For sentiment analysis,much effort has also been dedicated to designingeffective prompt templates to trigger the capabil-ity of Large Language Models (LLMs) such asRoBERTa (Liu et al., 2019) and GPT (Radfordet al., 2018) to predict sentiment polarities, e.g.,positive or negative. A prompt template typicallyconsists of prompt text and a label token set corre-sponding to the sentiment class. Gao et al. (2021)demonstrates that It was {good,ok,bad}. is a high-performing prompt template for sentiment analy-sis task. As Figure 1 shows, the input to LLM isA must-watch movie. It was [MASK]. , and the to-kenokis the most probable word over the labeltoken set.1https://github.com/repo4nlp/BackgroundIBM Confidential30.020.003…0.01goodokayaof…badPre-trained LMI really love this movie. It was [MASK].[MASK]Probability in softmax layer over vocabulary [1] BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, NAACL 2019IBM Research -Tokyogoodok……badLarge Language Model(frozen)A must-watch movie. It was [MASK].[MASK]probability distrution over vocabgood -> positive ok ->neutral bad -> negativeprobability rescaling, WFigure 1: Zero-shot prompt-based sentiment classifica-tion for a masked language model. The prompt is Itwas [MASK]. and the label token set is {good,ok,bad}which respectively stands for positive/neutral/negativesentiment polarities.However, two problems remain. First, an LLMis often biased to its pre-training data, leading topoor performance in prompt templates that theLLM have rarely seen. Second, when it comesto different domains, such as financial and food,re-designing appropriate prompt templates to adaptto new domains is usually required, which is time-consuming and inefficient. To mitigate the firstproblem, Zhao et al. (2021) proposed a probabilityrescaling method to calibrate the probability basedon the assumption that LLMs should NOT expresseither positive or negative sentiment when the inputis a meaningless sentence such as N/A.Motivated by this, we relax their assumptionand further hypothesize that a good LLM shouldbe capable of accurately predicting the sentimentof an \"absolute\" positive, neutral, or negative sen-tence. For example, the phrase \"thank you somuch\" mostly manifests an \"absolutely\" positive3923', metadata={'page': 0, 'source': '2023.findings-acl.242.pdf'}), Document(page_content='Findings of the Association for Computational Linguistics: ACL 2023 , pages 3923–3931July 9-14, 2023 ©2023 Association for Computational LinguisticsA Simple Yet Strong Domain-Agnostic De-bias Methodfor Zero-Shot Sentiment ClassificationYang Zhao†, Tetsuya Nasukawa†, Masayasu Muraoka†, and Bishwaranjan Bhattacharjee♢†IBM Research - Tokyo, 19-21 Nihonbashi Hakozaki-cho, Chuo City, Tokyo, 103-8510, Japan,♢IBM Research, Yorktown Heights, New York 10598, USAyangzhao@ibm.com ,{nasukawa,mmuraoka}@jp.ibm.com ,bhatta@us.ibm.comAbstractZero-shot prompt-based learning has mademuch progress in sentiment analysis, and con-siderable effort has been dedicated to design-ing high-performing prompt templates. How-ever, two problems exist; First, large languagemodels are often biased to their pre-trainingdata, leading to poor performance in prompttemplates that models have rarely seen. Sec-ond, in order to adapt to different domains, re-designing prompt templates is usually required,which is time-consuming and inefficient. Toremedy both shortcomings, we propose a sim-ple yet strong data construction method to de-bias a given prompt template, yielding a largeperformance improvement in sentiment analy-sis tasks across different domains, pre-trainedlanguage models, and prompt templates. Also,we demonstrate the advantage of using domain-agnostic generic responses over the in-domainground-truth data. We release the code here1.1 IntroductionOver the past few years, zero-shot prompt-basedlearning has become a de facto standard in manyNatural Language Processing (NLP) tasks wheretraining data is unavailable. For sentiment analysis,much effort has also been dedicated to designingeffective prompt templates to trigger the capabil-ity of Large Language Models (LLMs) such asRoBERTa (Liu et al., 2019) and GPT (Radfordet al., 2018) to predict sentiment polarities, e.g.,positive or negative. A prompt template typicallyconsists of prompt text and a label token set corre-sponding to the sentiment class. Gao et al. (2021)demonstrates that It was {good,ok,bad}. is a high-performing prompt template for sentiment analy-sis task. As Figure 1 shows, the input to LLM isA must-watch movie. It was [MASK]. , and the to-kenokis the most probable word over the labeltoken set.1https://github.com/repo4nlp/BackgroundIBM Confidential30.020.003…0.01goodokayaof…badPre-trained LMI really love this movie. It was [MASK].[MASK]Probability in softmax layer over vocabulary [1] BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, NAACL 2019IBM Research -Tokyogoodok……badLarge Language Model(frozen)A must-watch movie. It was [MASK].[MASK]probability distrution over vocabgood -> positive ok ->neutral bad -> negativeprobability rescaling, WFigure 1: Zero-shot prompt-based sentiment classifica-tion for a masked language model. The prompt is Itwas [MASK]. and the label token set is {good,ok,bad}which respectively stands for positive/neutral/negativesentiment polarities.However, two problems remain. First, an LLMis often biased to its pre-training data, leading topoor performance in prompt templates that theLLM have rarely seen. Second, when it comesto different domains, such as financial and food,re-designing appropriate prompt templates to adaptto new domains is usually required, which is time-consuming and inefficient. To mitigate the firstproblem, Zhao et al. (2021) proposed a probabilityrescaling method to calibrate the probability basedon the assumption that LLMs should NOT expresseither positive or negative sentiment when the inputis a meaningless sentence such as N/A.Motivated by this, we relax their assumptionand further hypothesize that a good LLM shouldbe capable of accurately predicting the sentimentof an \"absolute\" positive, neutral, or negative sen-tence. For example, the phrase \"thank you somuch\" mostly manifests an \"absolutely\" positive3923', metadata={'page': 0, 'source': '2023.findings-acl.242.pdf'})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "loader = PyPDFLoader(\"2023.findings-acl.242.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "for p in pages:\n",
    "    p.page_content = p.page_content.replace('\\n', ' ')\n",
    "# create the open-source embedding function\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# load it into Chroma\n",
    "db = Chroma.from_documents(pages, embedding_function)\n",
    "\n",
    "# query it\n",
    "query = \"Findings of the Association for Computational Linguistics\"\n",
    "docs = db.similarity_search(query,3)\n",
    "\n",
    "# print results\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "348bc037-a32e-4498-8808-e46649104561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "loader = PyPDFLoader(\"2023.findings-acl.242.pdf\")\n",
    "pages = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "03b912c5-6746-48c2-b514-7aed25c07998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Findings of the Association for Computational Linguistics: ACL 2023 , pages 3923–3931 July 9-14, 2023 ©2023 Association for Computational Linguistics A Simple Yet Strong Domain-Agnostic De-bias Method for Zero-Shot Sentiment Classification Yang Zhao†, Tetsuya Nasukawa†, Masayasu Muraoka†, and Bishwaranjan Bhattacharjee♢ †IBM Research - Tokyo, 19-21 Nihonbashi Hakozaki-cho, Chuo City, Tokyo, 103-8510, Japan, ♢IBM Research, Yorktown Heights, New York 10598, USA yangzhao@ibm.com ,{nasukawa,mmuraoka}@jp.ibm.com ,bhatta@us.ibm.com Abstract Zero-shot prompt-based learning has made much progress in sentiment analysis, and con- siderable effort has been dedicated to design- ing high-performing prompt templates. How- ever, two problems exist; First, large language models are often biased to their pre-training data, leading to poor performance in prompt templates that models have rarely seen. Sec- ond, in order to adapt to different domains, re- designing prompt templates is usually required, which is time-consuming and inefficient. To remedy both shortcomings, we propose a sim- ple yet strong data construction method to de- bias a given prompt template, yielding a large performance improvement in sentiment analy- sis tasks across different domains, pre-trained language models, and prompt templates. Also, we demonstrate the advantage of using domain- agnostic generic responses over the in-domain ground-truth data. We release the code here1. 1 Introduction Over the past few years, zero-shot prompt-based learning has become a de facto standard in many Natural Language Processing (NLP) tasks where training data is unavailable. For sentiment analysis, much effort has also been dedicated to designing effective prompt templates to trigger the capabil- ity of Large Language Models (LLMs) such as RoBERTa (Liu et al., 2019) and GPT (Radford et al., 2018) to predict sentiment polarities, e.g., positive or negative. A prompt template typically consists of prompt text and a label token set corre- sponding to the sentiment class. Gao et al. (2021) demonstrates that It was {good,ok,bad}. is a high- performing prompt template for sentiment analy- sis task. As Figure 1 shows, the input to LLM is A must-watch movie. It was [MASK]. , and the to- kenokis the most probable word over the label token set. 1https://github.com/repo4nlp/ Background IBM Confidential30.020.003…0.01goodokayaof…badPre-trained LMI really love this movie. It was [MASK].[MASK]Probability in softmax layer over vocabulary  [1] BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, NAACL 2019IBM Research -Tokyo goodok……badLarge Language Model(frozen)A must-watch movie. It was [MASK].[MASK]probability distrution over vocabgood -> positive ok ->neutral bad -> negativeprobability rescaling, WFigure 1: Zero-shot prompt-based sentiment classifica- tion for a masked language model. The prompt is It was [MASK]. and the label token set is {good,ok,bad} which respectively stands for positive/neutral/negative sentiment polarities. However, two problems remain. First, an LLM is often biased to its pre-training data, leading to poor performance in prompt templates that the LLM have rarely seen. Second, when it comes to different domains, such as financial and food, re-designing appropriate prompt templates to adapt to new domains is usually required, which is time- consuming and inefficient. To mitigate the first problem, Zhao et al. (2021) proposed a probability rescaling method to calibrate the probability based on the assumption that LLMs should NOT express either positive or negative sentiment when the input is a meaningless sentence such as N/A. Motivated by this, we relax their assumption and further hypothesize that a good LLM should be capable of accurately predicting the sentiment of an \"absolute\" positive, neutral, or negative sen- tence. For example, the phrase \"thank you so much\" mostly manifests an \"absolutely\" positive3923' metadata={'source': '2023.findings-acl.242.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "print(pages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3363529f-b29c-44cb-8358-952af11b046d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "98e00dbe-e963-48ea-a8e4-a4023f352657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='standing by generative pre-training.\\nAlec Radford, Jeff Wu, Rewon Child, David Luan,\\nDario Amodei, and Ilya Sutskever. 2019. Language\\nmodels are unsupervised multitask learners.\\nRichard Socher, Alex Perelygin, Jean Wu, Jason\\nChuang, Christopher D. Manning, Andrew Ng, and\\nChristopher Potts. 2013. Recursive deep models for\\nsemantic compositionality over a sentiment treebank.\\nInProceedings of the 2013 Conference on Empiri-\\ncal Methods in Natural Language Processing , pages\\n1631–1642, Seattle, Washington, USA. Association\\nfor Computational Linguistics.\\nZihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and\\nSameer Singh. 2021. Calibrate before use: Improv-\\ning few-shot performance of language models. In\\nProceedings of the 38th International Conference\\non Machine Learning , volume 139 of Proceedings\\nof Machine Learning Research , pages 12697–12706.\\nPMLR.3928', metadata={'page': 5, 'source': '2023.findings-acl.242.pdf'}), Document(page_content='standing by generative pre-training. Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Language models are unsupervised multitask learners. Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Ng, and Christopher Potts. 2013. Recursive deep models for semantic compositionality over a sentiment treebank. InProceedings of the 2013 Conference on Empiri- cal Methods in Natural Language Processing , pages 1631–1642, Seattle, Washington, USA. Association for Computational Linguistics. Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021. Calibrate before use: Improv- ing few-shot performance of language models. In Proceedings of the 38th International Conference on Machine Learning , volume 139 of Proceedings of Machine Learning Research , pages 12697–12706. PMLR.3928', metadata={'page': 5, 'source': '2023.findings-acl.242.pdf'}), Document(page_content='standing by generative pre-training. Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Language models are unsupervised multitask learners. Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Ng, and Christopher Potts. 2013. Recursive deep models for semantic compositionality over a sentiment treebank. InProceedings of the 2013 Conference on Empiri- cal Methods in Natural Language Processing , pages 1631–1642, Seattle, Washington, USA. Association for Computational Linguistics. Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021. Calibrate before use: Improv- ing few-shot performance of language models. In Proceedings of the 38th International Conference on Machine Learning , volume 139 of Proceedings of Machine Learning Research , pages 12697–12706. PMLR.3928', metadata={'page': 5, 'source': '2023.findings-acl.242.pdf'})]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc50d1e8-d117-4070-8cfb-18e4d1ca73d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standing by generative pre-training.\n",
      "Alec Radford, Jeff Wu, Rewon Child, David Luan,\n",
      "Dario Amodei, and Ilya Sutskever. 2019. Language\n",
      "models are unsupervised multitask learners.\n",
      "Richard Socher, Alex Perelygin, Jean Wu, Jason\n",
      "Chuang, Christopher D. Manning, Andrew Ng, and\n",
      "Christopher Potts. 2013. Recursive deep models for\n",
      "semantic compositionality over a sentiment treebank.\n",
      "InProceedings of the 2013 Conference on Empiri-\n",
      "cal Methods in Natural Language Processing , pages\n",
      "1631–1642, Seattle, Washington, USA. Association\n",
      "for Computational Linguistics.\n",
      "Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and\n",
      "Sameer Singh. 2021. Calibrate before use: Improv-\n",
      "ing few-shot performance of language models. In\n",
      "Proceedings of the 38th International Conference\n",
      "on Machine Learning , volume 139 of Proceedings\n",
      "of Machine Learning Research , pages 12697–12706.\n",
      "PMLR.3928\n",
      "standing by generative pre-training.\n",
      "Alec Radford, Jeff Wu, Rewon Child, David Luan,\n",
      "Dario Amodei, and Ilya Sutskever. 2019. Language\n",
      "models are unsupervised multitask learners.\n",
      "Richard Socher, Alex Perelygin, Jean Wu, Jason\n",
      "Chuang, Christopher D. Manning, Andrew Ng, and\n",
      "Christopher Potts. 2013. Recursive deep models for\n",
      "semantic compositionality over a sentiment treebank.\n",
      "InProceedings of the 2013 Conference on Empiri-\n",
      "cal Methods in Natural Language Processing , pages\n",
      "1631–1642, Seattle, Washington, USA. Association\n",
      "for Computational Linguistics.\n",
      "Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and\n",
      "Sameer Singh. 2021. Calibrate before use: Improv-\n",
      "ing few-shot performance of language models. In\n",
      "Proceedings of the 38th International Conference\n",
      "on Machine Learning , volume 139 of Proceedings\n",
      "of Machine Learning Research , pages 12697–12706.\n",
      "PMLR.3928\n",
      "source Prompt Text Label Token Set\n",
      "Gao et al. (2021) <S> It was [MASK]. {good,ok,bad}\n",
      "Liu et al. (2021) <S> The sentiment is [MASK]. {positive,neutral,negative}\n",
      "Table 1: Widely-used prompts in mainstream sentiment analysis task.\n",
      "Fto form a frequent utterance set S, as a set of\n",
      "generic responses to be sentiment-labeled.\n",
      "Step 2: Annotation.\n",
      "We employ a pre-defined positive word list Lpos\n",
      "containing 2,006 words and a negative word list\n",
      "Lnegcontaining 4,783 words from (Hu and Liu,\n",
      "2004) and automatically tag the sentiment polarity\n",
      "tiof each utterance uiinSin the following way:\n",
      "1.ifuicontains more than one positive word in\n",
      "listLposand no negative word in list Lneg:\n",
      "(a) tag ti\"positive\" if the number of negation\n",
      "words is an even number, or (b) tag ti\"neg-\n",
      "ative\" if the number of negation words is an\n",
      "odd number.\n",
      "2.ifuicontains no positive word in list Lpos\n",
      "and more than one negative word in list Lneg:\n",
      "(a) tag ti\"negative\" if the number of negation\n",
      "words is an even number, or (b) tag ti\"pos-\n",
      "itive\" if the number of negation words is an\n",
      "odd number.\n",
      "3.ifuicontains no positive word in Lposand no\n",
      "negative word in Lneg, then tag ti\"neutral\".\n",
      "We use labeled instances ( ui,ti) of each class to\n",
      "train the rescaling parameter W.\n",
      "3 Experiment\n",
      "3.1 Experimental Details\n",
      "We use Cornell Movie-Dialog Corpus3(D)\n",
      "(Danescu-Niculescu-Mizil and Lee, 2011) which\n",
      "is under creative commons license and extract\n",
      "304,713 dialogue utterance ( U). After dedupli-\n",
      "cation and removal of interrogative sentences4, we\n",
      "set frequency threshold ( F) to 3 to obtain 2,211\n",
      "sentences. After automatic annotation, we finally\n",
      "yielded 274 positive instances, 176 negative in-\n",
      "stances, and 1,761 neutral instances. We selected\n",
      "100 instances for each class and in total, 300\n",
      "sentiment-labeled instances to train the parameter\n",
      "W. Please refer to the Appendix A for examples.\n",
      "3https://www.kaggle.com/datasets/rajathmc/cornell-\n",
      "moviedialog-corpus\n",
      "4It is often difficult to determine the sentiment polarity of\n",
      "interrogative sentences such as \"is it good?\".Quality Assessment of Automatic Annotation\n",
      "To assess the quality of automatic annotation, we\n",
      "assigned a human annotator5to rate 300 instances\n",
      "(100 instances per class) by judging whether the\n",
      "instance is positive or not for 100 automatically an-\n",
      "notated positive instances. The same process was\n",
      "followed for the negative and neutral classes. The\n",
      "results show that out of the 300 instances evaluated,\n",
      "43 instances displayed inconsistencies with human\n",
      "judgment, resulting in an automatic annotation ac-\n",
      "curacy of 0.86.\n",
      "For training, we split the data into a training set\n",
      "with 240 instances and dev set with 60 instances\n",
      "and select the best model based on the performance\n",
      "of the dev set. Then, we test the best model on all\n",
      "the datasets in Table 2. For the evaluation metric,\n",
      "we use accuracy for datasets whose label class is\n",
      "balanced (SST-2, IMDB, Yelp, and Amazon) and\n",
      "Macro-F1 for the datasets whose label class is un-\n",
      "balanced (Phrasebank, airline, and debate). We\n",
      "used the arithmetic average (Ave.) instead of the\n",
      "weighted average because we view each dataset and\n",
      "its representing domain equally important6. We use\n",
      "one A100 GPU to train the model by setting the\n",
      "batch size to 10, the learning rate to 1e-5, and the\n",
      "number of epochs to 100. It takes half an hour to\n",
      "finish the whole training. The parameters of LLMs\n",
      "are frozen during training.\n",
      "Dataset Domain #of classes Size\n",
      "IMDB Movie 2 1,000\n",
      "Yelp Restaurant 2 1,000\n",
      "Amazon Product 2 1,000\n",
      "SST-2 Movie 2 9,613\n",
      "Airline Operation 3 10,445\n",
      "Debate Politics 3 5,354\n",
      "Phrasebank Finance 3 2,264\n",
      "Table 2: Statistics of sentence-level sentiment datasets.\n",
      "It is worth noting that no training/dev/test split is needed\n",
      "because we use the whole dataset for evaluation only.\n",
      "5The annotator is based in Japan.\n",
      "6We experimented with weighted average according to\n",
      "the size of each dataset in Table 2 and observed even better\n",
      "performance of the proposed method.3925\n"
     ]
    }
   ],
   "source": [
    "for d in docs:\n",
    "    print(d.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "743b00e4-37d8-49b6-9023-e68045e611bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Users/xyd/anaconda3/lib/python3.11/site-packages/slither_analyzer-0.10.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: langchain_community in /Users/xyd/anaconda3/lib/python3.11/site-packages (0.0.28)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/xyd/anaconda3/lib/python3.11/site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/xyd/anaconda3/lib/python3.11/site-packages (from langchain_community) (2.0.22)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/xyd/anaconda3/lib/python3.11/site-packages (from langchain_community) (3.8.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/xyd/anaconda3/lib/python3.11/site-packages (from langchain_community) (0.6.4)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.31 in /Users/xyd/anaconda3/lib/python3.11/site-packages (from langchain_community) (0.1.32)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/xyd/anaconda3/lib/python3.11/site-packages (from langchain_community) (0.1.27)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/xyd/anaconda3/lib/python3.11/site-packages (from langchain_community) (1.24.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/xyd/anaconda3/lib/python3.11/site-packages (from langchain_community) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/xyd/anaconda3/lib/python3.11/site-packages (from langchain_community) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/xyd/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/xyd/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (3.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/xyd/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/xyd/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/xyd/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/xyd/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/xyd/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/xyd/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/xyd/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3 in /Users/xyd/anaconda3/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.31->langchain_community) (4.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/xyd/anaconda3/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.31->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/xyd/anaconda3/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.31->langchain_community) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/xyd/anaconda3/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.31->langchain_community) (1.10.13)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/xyd/anaconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.9.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/xyd/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain_community) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/xyd/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain_community) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/xyd/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain_community) (2023.7.22)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/xyd/anaconda3/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.8.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/xyd/anaconda3/lib/python3.11/site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.31->langchain_community) (1.3.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/xyd/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.31->langchain_community) (2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/xyd/anaconda3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install langchain_community"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
